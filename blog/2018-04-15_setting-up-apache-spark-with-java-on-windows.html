<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>Mathieu De Coster - Setting up Apache Spark with Java on Windows</title>

    <meta charset="UTF-8">
    <meta name="description" content="Webpage of Mathieu De Coster">
    <meta name="author" content="Mathieu De Coster">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#fafafa" media="(prefers-color-scheme: light)">
    <meta name="theme-color" content="#333" media="(prefers-color-scheme: dark)">

    <link rel="stylesheet" href="../styles/style.css">
    <!-- favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="../icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../icons/favicon-16x16.png">
    <link rel="manifest" href="../icons/site.webmanifest">
    <link rel="mask-icon" href="../icons/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="../icons/favicon.ico">
    <meta name="msapplication-TileColor" content="#00aba9">
    <meta name="msapplication-config" content="../icons/browserconfig.xml">
    
<link rel="stylesheet"
      href="../styles/atom-one-lightdark.css">

</head>

<body>
    <header>
        <h1>Mathieu De Coster</h1>
        <nav>
                
                        <a href="../index.html">About</a>
                
                        <a href="../research.html">Research</a>
                
                        <a href="../blog/page0.html">Blog</a>
                    
                
                        <a href="../contact.html">Contact</a>
        </nav>
    </header>
    
    
<section id="post">
    <h1>Setting up Apache Spark with Java on Windows</h1>
    <p class="post-preview-date">15 April 2018</p>
    <p>Setting up Spark for use in Java in Windows is fairly easy if you know what to do. I will take you through the steps needed here.</p>
<p>We will use the following technologies, which you should already have installed and set up:</p>
<ul>
<li>Java 8</li>
<li>Apache Maven</li>
<li>IntelliJ IDEA (or another IDE set up to work with Maven)</li>
</ul>
<p>You should know how to work with Maven.</p>
<p>My set up uses the <code>D:</code> volume, but you should be able to substitute it for <code>C:</code> if you prefer.</p>
<h2>Installing Spark</h2>
<p>First, you need to download and install Apache Spark.
Go to <a href="https://archive.apache.org/dist/spark/spark-2.0.0">this page</a> and download the archive named
<code>spark-2.0.0-bin-hadoop2.7.tgz</code>.</p>
<p>Extract the archive to <code>D:\spark</code> such that you now have the folders <code>D:\spark\bin</code> etcetera.</p>
<p>Now download <a href="https://codeload.github.com/srccodes/hadoop-common-2.2.0-bin/zip/master">Hadoop</a>. Copy
<code>bin\winutils.exe</code> to the <code>D:\spark\bin</code> folder.</p>
<h3>Environment variables</h3>
<p>Go to your system's environment variables by typing &quot;environment variables&quot; in the Start menu and selecting &quot;Edit the system environment variables&quot;.
Add two new variables under the &quot;user variables&quot; section:</p>
<ul>
<li><code>HADOOP_HOME</code> with the value <code>D:\spark</code></li>
<li><code>SPARK_HOME</code> with the value <code>D:\spark\bin</code></li>
</ul>
<p>Now edit the <code>PATH</code> variable and add two new entries:</p>
<ul>
<li><code>%HADOOP_HOME%</code></li>
<li><code>%SPARK_HOME%</code></li>
</ul>
<p>Close all windows by clicking &quot;OK&quot;.</p>
<h3>Testing the installation</h3>
<p>Open a command prompt (Windows+R, enter <code>cmd</code> and press the Return key) and execute <code>spark-shell.cmd</code>. This should launch the Spark shell
and among other things print the Spark logo as ASCII art.</p>
<h2>Setting up a Maven project</h2>
<p>Now we will create a Maven project so that we can use Spark from Java.
Create a new Maven project with the quickstart archetype <code>maven-archetype-quickstart</code>. In IntelliJ you can do this through
File &gt; New &gt; Project... and selecting Maven in the list, then checking &quot;Create from archetype&quot; and selecting the quickstart prototype.</p>
<p>Open <code>pom.xml</code> and add the following repository:</p>
<pre><code class="language-xml">&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;cloudera&lt;/id&gt;
        &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;
</code></pre>
<p>Also add these two dependencies:</p>
<pre><code class="language-xml">&lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;junit&lt;/groupId&gt;
      &lt;artifactId&gt;junit&lt;/artifactId&gt;
      &lt;version&gt;4.11&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;
      &lt;version&gt;2.0.0-cloudera1-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;
      &lt;version&gt;2.0.0-cloudera1-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<h3>Java</h3>
<p>Now edit the <code>App.java</code> file that was created by the Maven archetype and enter this code below the <code>package</code> statement:</p>
<pre><code class="language-java">import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.sql.SparkSession;
import scala.Tuple2;

import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.util.*;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

/**
 * Hello world!
 */
public class App {
    private static final Pattern SPACE = Pattern.compile(&quot; &quot;);
    private static final String INPUT_PATH = &quot;src/main/resources/input.txt&quot;;

    public static void main(String[] args) throws IOException {
        SparkSession spark = SparkSession
                .builder()
                .appName(&quot;Java_word_count&quot;)
                .master(&quot;local[4]&quot;) // Replace 4 with the number of cores on your processor
                .config(&quot;spark.sql.warehouse.dir&quot;, &quot;file:///c:/tmp/spark-warehouse&quot;)
                .getOrCreate();

        JavaRDD&lt;String&gt; lines = spark.read().textFile(INPUT_PATH).javaRDD();

        JavaRDD&lt;String&gt; words = lines.flatMap(s -&gt; Arrays.asList(SPACE.split(s)).iterator());

        JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(s -&gt; new Tuple2&lt;&gt;(s, 1));

        JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey((i1, i2) -&gt; i1 + i2);

        JavaPairRDD&lt;Integer, String&gt; swapped = counts.mapToPair(Tuple2::swap);
        swapped = swapped.sortByKey();

        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = swapped.mapToPair(Tuple2::swap).collect();
        for (Tuple2&lt;?, ?&gt; tuple : output) {
            System.out.println(tuple._1() + &quot;: &quot; + tuple._2());
        }
        spark.stop();
    }
}
</code></pre>
<p>Now we just need an input text file. Andrej Karpathy has an example of Character level Recurrent Neural Networks on Github,
and on the repository there is an input file available with some Shakespeare plays. Download the text file from <a href="https://github.com/karpathy/char-rnn/tree/master/data/tinyshakespeare">the repository</a> and save it in <code>src\main\resources</code>.</p>
<p>You should now be able to run the main function in <code>App.java</code> and obtain a list of word counts after a lot of Spark output.</p>
<p>Congratulations, you have set up Apache Spark for use with Java!</p>

</section>

<script src="../scripts/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<noscript>You appear to have disabled JavaScript. No worries, the only thing that will not work is code highlighting.</noscript>


</body>

</html>
